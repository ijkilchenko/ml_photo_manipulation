# ml_photo_manipulation
Writing some scripts to manage collection of photos using ML (e.g. sort by image similarity, etc.)

## Motivation
When maintaining a photo library, duplicates become a problem. They are a waste of space (and time, given it could take a long time to find a duplicate manually). Sometimes we take too many similar photos producing near-duplicates. This library attempts to solve these problems by tapping into unsupervised features generated by some convolutional neural network (e.g. xception). Using this library, you can prefix all images files with a rank such that duplicates or "near" duplicates appear next to each other (for easy manual deletion).

## Approach
For each image, I generate numeric features using a pretrained model. Then I sort (actually just prefix images with a rank -- we'll let the OS sort the images) all images in the following way:
* Take any photo, find another photo that is closest to the first via euclidean distance between the feature vectors. 
* Take the last photo and find another photo (without replacement so to speak) and append it to the list we are maintaining.
* Continue... 
This way we end up with a list of photos where any adjacent pair is close in terms of euclidean distance between the feature vectors. 

## Commands
If you are using `virtualenv`, do `source myenv/bin/activate`

### Resize
For testing purposes, it might be easier to work with smaller images at first. Check how it works and then go back and process the original photos. The default resizing is 10% of height and 10% of width. 

Run `python resize.py --in-path /path/to/image/folder --out-path /path/to/image/folder2`

### Featurize
Use a pretrained model to generate numeric features and save these in `features.csv` in the `path` that you provide. 

Run `python featurize.py --path /path/to/image/folder`

### Analyze
Pick up `features.csv` and append a column called `R` for Rank which shows which images should be adjacent once sorted. 

Run `python analyze.py --path /path/to/image/folder`
This script runs inference on all the images so it might be slow. Add a `--fast` constraint to do a less exhaustive search.

### Refresh
`--dry-run` goes through all the motions but doesn't modify files (use at your own risk).

`--sort-by-vec` uses the `R` column of `features.csv` for sorting. 

Run `python refresh.py --path /path/to/image/folder --dry-run`

Run `python refresh.py --path /path/to/image/folder --sort-by-vec`

or do it all as one command (remove `--dry-run`):

```
export IN_PATH=/path/to/image/folder &&
export OUT_PATH=/path/to/image/folder2 &&
python resize.py --in-path $IN_PATH --out-path $OUT_PATH --resize-factor 0.05 &&
python featurize.py --path $OUT_PATH --depth 1 && 
python analyze.py --path $OUT_PATH --fast && 
python refresh.py --path $OUT_PATH --sort-by-vec --dry-run
```

and a more thorough one command (deeper depth, larger resize factor, less constraints on `analyze`):

```
export IN_PATH=/path/to/image/folder &&
export OUT_PATH=/path/to/image/folder2 &&
python resize.py --in-path $IN_PATH --out-path $OUT_PATH --resize-factor 0.5 &&
python featurize.py --path $OUT_PATH --depth 4 && 
python analyze.py --path $OUT_PATH && 
python refresh.py --path $OUT_PATH --sort-by-vec
```